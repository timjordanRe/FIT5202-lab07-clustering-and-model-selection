{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIT5202 Data processing for big data\n",
    "\n",
    "##  Activity: Machine Learning with Spark (Model Selection and Persistance)\n",
    "\n",
    "In this part of the tutorial, we want to look into 2 things 1) Model Selection and 2)Persisting the Model.\n",
    "The sequence of steps below create the ML Pipeline for the Decision Tree Model that we did in Week 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your code here\n",
    "from pyspark import SparkConf # Spark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "spark_conf = SparkConf()\\\n",
    "            .setMaster(\"local[*]\")\\\n",
    "            .setAppName(\"ML-Classification\")\n",
    "\n",
    "spark = SparkSession.builder.config(conf=spark_conf).getOrCreate()\n",
    "spark.sparkContext.setLogLevel('ERROR')\n",
    "\n",
    "df = spark.read.csv('bank.csv', header = True, inferSchema = True)\n",
    "cols = df.columns\n",
    "\n",
    "# First, save the category in the category columns list.\n",
    "categoryInputCols = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'poutcome']\n",
    "numericInputCols = ['age', 'balance', 'duration', 'campaign', 'pdays', 'previous']\n",
    "categoryOutputCol = 'deposit'\n",
    "categoryCols = categoryInputCols+[categoryOutputCol]\n",
    "\n",
    "train, test = df.randomSplit([0.7, 0.3], seed = 2020)\n",
    "\n",
    "outputCols=[f'{x}_index' for x in categoryInputCols]\n",
    "outputCols.append('label')\n",
    "inputIndexer = StringIndexer(inputCols=categoryCols, outputCols=outputCols)\n",
    "\n",
    "inputCols_OHE = [x for x in outputCols if x!='label']\n",
    "outputCols_OHE = [f'{x}_vec' for x in categoryInputCols]\n",
    "encoder = OneHotEncoder(inputCols=inputCols_OHE,outputCols=outputCols_OHE)\n",
    "\n",
    "inputCols=outputCols_OHE\n",
    "assemblerInputs = outputCols_OHE + numericInputCols\n",
    "assembler = VectorAssembler(inputCols = assemblerInputs, outputCol=\"features\")\n",
    "\n",
    "dt = DecisionTreeClassifier(featuresCol = 'features', labelCol = 'label', maxDepth = 3)\n",
    "\n",
    "stage_1 = inputIndexer\n",
    "stage_2 = encoder\n",
    "stage_3 = assembler\n",
    "stage_4 = dt\n",
    "\n",
    "stages = [stage_1,stage_2,stage_3,stage_4]\n",
    "\n",
    "pipeline = Pipeline(stages = stages)\n",
    "pipelineModel = pipeline.fit(train)\n",
    "predictions = pipelineModel.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.select('features','label','prediction').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing the parameters in the Model\n",
    "You can use <code>extractParamMap()</code> to see the list of parameters for the particular estimater. For more details on this, refer to the <a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.ml.html\" target=\"_BLANK\">Spark Documentation</a>. If it is a PipelineModel, you need to do <code>model.stages[-1].extractParamMap()</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelineModel.stages[-1].extractParamMap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation and Hyperparameter Tuning\n",
    "Last week we looked into Decision Trees, out of the different parameters, let's take <code>maxBins</code> and <code>maxDepth</code> as the two hyperparamters. We used <code>maxDepth=3</code> as the default value, but <strong> is 3 the optimum hyperparameter value for the model?</strong>. This is something we want to achieve using the HyperParameter Tuning.\n",
    "We could also manually tune the hyperparameters using educated guesses, training the model, evaluating its performance and repeating the steps but it will be tedious. <a href=\"https://towardsdatascience.com/cross-validation-and-hyperparameter-tuning-how-to-optimise-your-machine-learning-model-13f005af9d7d\" target=\"_BLANK\">Read More</a> \n",
    "\n",
    "One popular approach is to create a grid of hyper-parameters we want to optimze with the values we want to try out. In Spark, we can use <code>ParamGridBuilder</code> to define the hyperparameters for any estimator. Since, the model needs to be evaluated at every parameter combination, we need to also define an <code>Evaluator</code>.\n",
    "\n",
    "Finally, when we use this with the <code>CrossValidator (K-Fold)</code>, for each fold (i.e. the train/test split), it tries out all the possible combination of the hyper-parameters and evaluates the performance of each instance. Finally, based on the evaluaton, it gives us the best model i.e. the best combination of hyperparameters to use.\n",
    "\n",
    "Let's try to tune the parameters for our <code>DecisionTree</code> Model. Since we are using the <code>Pipeline</code>, we can directly plugin the PipelineModel to the CrossValidator as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a grid specifying all the parameters and their values we want to test our model with. We are assigning a series of values for the hyperparameters <code>maxDepth</code> and <code>maxBins</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator,CrossValidatorModel\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "# Create ParamGrid for Cross Validation\n",
    "dtparamGrid = (ParamGridBuilder()\n",
    "             .addGrid(dt.maxDepth, [2, 5, 10, 20, 30])\n",
    "             .addGrid(dt.maxBins, [10, 20, 40, 80, 100])\n",
    "             .build())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an evaluator to be used for evaluating the model \n",
    "dtevaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's declare the <code>CrossValidator</code> which takes the estimator, paramgrid and evaluator as input. Also, we need to specify the number of folds we want to test against."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 3-fold CrossValidator\n",
    "dtcv = CrossValidator(estimator = pipeline,\n",
    "                      estimatorParamMaps = dtparamGrid,\n",
    "                      evaluator = dtevaluator,\n",
    "                      numFolds = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where we train our cross-validator, as the CV trains/evaluates the model for every fold of data across all possible parameter combinations, <strong style=\"color:red\">this step is very expensive and might take some time to finsh.</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cross validations\n",
    "dtcvModel = dtcv.fit(train)\n",
    "print(dtcvModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the Best Model\n",
    "Now that we have finished running the CrossValidator, we can obtain the model with the best combination of hyperparameters using <code>.bestModel</code>. Also <code>bestModel.stages[-1]._java_obj.paramMap()</code> gives you the hyperparameteres with the optimum values selected by the CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the best model and the optimum parameters selected from the Cross Validation \n",
    "bestModel= dtcvModel.bestModel\n",
    "print(bestModel.stages)\n",
    "print('Best Param for DT: ', bestModel.stages[-1]._java_obj.paramMap())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Persistance (Saving and Loading the Model)\n",
    "For simple models (i.e. without pipelines), you can simply save the model by using <code>model.save('path')</code> and load it using <code>.load('model_path')</code>.\n",
    "\n",
    "You can also save and load whole PipelineModel in Spark using save/load methods.\n",
    "In the following example, we will save the <strong>bestModel</strong> we obtained from the <strong>Model Selection</strong> and Load it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saves the model to the filesystem\n",
    "bestModel.save('bank_subscriber_prediction_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the Pipeline Model From the filesystem\n",
    "from pyspark.ml import PipelineModel\n",
    "pipelineModel = PipelineModel.load('bank_subscriber_prediction_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above step loads the same model again, you can check the hyperparameters that we obtained earlier for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pipelineModel.stages[-1]._java_obj.paramMap())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:rgba(0,109,174,0.2);padding:10px;border-radius:4px\"><strong style=\"color:#006DAE\">TODO: </strong>\n",
    "    You can load this model in a separate file and try to generate some predictions off it directly by using some data instances from the bank.csv file.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TrainValidation Split\n",
    "This is another aproach in Spark for hyper-parameter tuning. You can refer to the Spark Documentation for more details <a href=\"https://spark.apache.org/docs/latest/ml-tuning.html#train-validation-split\" target=\"_BLANK\">[Ref]</a>. Compared to CrossValidation, this approach is less expensive since it evaluates each combination of parameters just once as opposed to k-times in CV. The example below demonstrates the use of TrainValidationSplit. We have used the same parameter combination with the same pipeline model and evaluator.\n",
    "\n",
    "Note that, one input parameter that is different than CV is <code>trainRatio</code>, which specifies the split percentage for train/validation data. \n",
    "When you run this vs the Cross-Validation version, you will notice signficant difference in the time taken which is due to the fact that this approach only evaluates the combination of parameters once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import TrainValidationSplit\n",
    "dtparamGrid = (ParamGridBuilder()\n",
    "             .addGrid(dt.maxDepth, [2, 5, 10, 20, 30])\n",
    "             .addGrid(dt.maxBins, [10, 20, 40, 80, 100])\n",
    "             .build())\n",
    "\n",
    "dttv = TrainValidationSplit(estimator = pipeline,\n",
    "                      estimatorParamMaps = dtparamGrid,\n",
    "                      evaluator = dtevaluator,\n",
    "                      trainRatio = 0.8)\n",
    "model = dttv.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestModel_tv = model.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bestModel_tv.stages[-1]._java_obj.paramMap())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "<a href=\"https://medium.com/@srinivasugaddam/machine-learning-model-selection-and-hyperparameter-tuning-using-pyspark-80dd8c1bfc56\" target=\"_BLANK\">1. Machine Learning Model Selection and Hyperparameter Tuning using PySpark</a>\n",
    "\n",
    "<a href=\"https://spark.apache.org/docs/latest/ml-tuning.html\" target=\"_BLANK\">2. Spark ML Tuning</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
